---
title: "Tarea 5. Diferenciación e integración numérica."
author: "Vazquez Cisneros Dario Emanuel"
format: 
  html:
    grid: 
      body-width: 1000px
editor: visual
jupyter: python3
---

Importamos packages y funciones necesarias:

```{python}
#| code-fold: true

import matplotlib.pyplot as plt
import numpy as np
import math
from scipy.interpolate import lagrange
from numpy.polynomial.polynomial import Polynomial
from scipy.interpolate import CubicSpline

import plotly.graph_objects as go
from scipy.differentiate import derivative
import numdifftools as nd
from scipy.stats import norm
from scipy import integrate

```

# Ejercicio 1.

Para cada una de las siguientes funciones:

-   Realiza la respectiva gráfica en el intervalo dado.

-   Compara las gráficas de las derivadas aproximadas de la función `derivative` de `Scipy`, con dos tamaños de paso utilizando la función `nd.Derivative` y la derivada *exacta* en tal intervalo.

-   Compara las gráficas de las segundas derivadas aproximadas con dos tamaños de paso utilizando la función `nd.Derivative` y la segunda derivada *exacta* en tal intervalo.

-   Realiza las gráficas de los errores absolutos en cada caso.

a)  $f(x)=e^{2x}-cos 2x$, $x\in [0,2]$ Realiza la respectiva gráfica en el intervalo dado.

```{python}
#| code-fold: true
#| fig-align: 'center'

f = lambda x:np.exp(2*x)-np.cos(2*x)

x_values = np.linspace(0, 2, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,  f(x_values), color="firebrick")
plt.grid()
plt.show()
```

Primera derivada

```{python}
#| code-fold: true
#| warning: false
#| message: false

derf = lambda x: 2*np.exp(2*x)+2*np.sin(2*x)

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_005 = nd.Derivative(f, step=0.05, method='central', order=2)


fig = go.Figure()
# Aproximación de la derivada con los tamaños de paso 
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_005(x_values), mode='lines', name='h=0.05', line=dict(color='royalblue', width=1)))
# Aproximación de la derivada con derivative de Scipy
fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))
# Derivada "exacta"
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=1)))

fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la primera derivada

```{python}
#| code-fold: true

fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_005(x_values)), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-np.gradient(f(x_values), x_values, edge_order=2)), mode='lines', name='np.gradient', line=dict(color='red', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Segunda derivada

```{python}
#| code-fold: true


dderf = lambda x: 4*np.exp(2*x)+4*np.cos(2*x)

a = 0 
b= 2* np.pi

ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_025 = nd.Derivative(f, step=0.25, method='central', order=2, n = 2)
fig = go.Figure()

x_values = np.linspace(a, b, 500)

fig.add_trace(go.Scatter(x= x_values, y= ddf_025(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()

```

Realiza las gráficas de los errores absolutos

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-df_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))

fig.update_layout(
    title="Gráfica de errores segunda derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

b)  $f(x)=log(x+2)-(x+1)^2$, $x\in [0,5]$

```{python}
#| code-fold: true
#| fig-align: 'center'

f = lambda x:np.log(x+2)-(x+1)**2

x_values = np.linspace(0, 5, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,  f(x_values), color="firebrick")
plt.grid()
plt.show()
```

Primera derivada

```{python}
#| code-fold: true
#| warning: false
#| message: false

derf = lambda x: -2*x+1/(x+2)-2

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_005 = nd.Derivative(f, step=0.05, method='central', order=2)


fig = go.Figure()
# Aproximación de la derivada con los tamaños de paso 
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_005(x_values), mode='lines', name='h=0.05', line=dict(color='royalblue', width=1)))
# Aproximación de la derivada con derivative de Scipy
fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))
# Derivada "exacta"
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=1)))

fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la primera derivada

```{python}
#| code-fold: true

fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_005(x_values)), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-np.gradient(f(x_values), x_values, edge_order=2)), mode='lines', name='np.gradient', line=dict(color='red', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Segunda derivada

```{python}
#| code-fold: true


dderf = lambda x: -1/(np.log(10)*(x+2)**2)-2

a = 0 
b= 2* np.pi

ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_025 = nd.Derivative(f, step=0.25, method='central', order=2, n = 2)
fig = go.Figure()

x_values = np.linspace(a, b, 500)

fig.add_trace(go.Scatter(x= x_values, y= ddf_025(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la primera derivada

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

def ddf_005(x):
    # Your finite difference implementation for h=0.05
    return (f(x + 0.05) - 2*f(x) + f(x - 0.05)) / (0.05**2)

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))

fig.update_layout(
    title="Gráfica de errores segunda derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

c)  $f(x)=\sqrt{x} sen(x^2)$, $x\in [0,\pi]$

Gráfica de la función.

```{python}
#| code-fold: true
#| fig-align: 'center'


f = lambda x: np.sqrt(x)*np.sin(x**2)

x_values = np.linspace(0, np.pi, 200)

plt.figure(figsize=(8,6))
plt.plot(x_values,  f(x_values), color = "darkred", linewidth=1.5)
plt.grid()
plt.show()
```

Derivada : $f'(x)= 2x\sqrt{x}\,cos(x^2)+\frac{sen(x^2)}{2\sqrt{x}}$. Aproximaciones con dos tamaños de paso $h=0.05$ y $h=0.1$

```{python}
#| code-fold: true
#| warning: false
#| message: false

derf = lambda x: 2* x * np.sqrt(x) * np.cos(x**2)+ (np.sin(x**2)/2) * (1/np.sqrt(x))

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_005 = nd.Derivative(f, step=0.05, method='central', order=2)


fig = go.Figure()
# Aproximación de la derivada con los tamaños de paso 
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_005(x_values), mode='lines', name='h=0.05', line=dict(color='royalblue', width=1)))
# Aproximación de la derivada con derivative de Scipy
fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))
# Derivada "exacta"
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=1)))

fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la primera derivada.

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))

fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Segunda derivada: $f''(x)= 4 \sqrt{x}\, cos(x^2)-sen(x^2)\left(4 x^2 \sqrt{x}+\frac{1}{4x\sqrt{x}} \right)$. Aproximaciones con $h=0.05$ y $h=0.1$

```{python}
#| code-fold: true
#| warning: false

dderf = lambda x: 4* np.sqrt(x) * np.cos(x**2) -np.sin(x**2) *(4* x **2 * np.sqrt(x)+1/(4*x*np.sqrt(x)))

# Funciones de numdifftools para la segunda derivada
ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_005 = nd.Derivative(f, step=0.05, method='central', order=2, n = 2)

fig = go.Figure()
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_005(x_values), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()

```

Gráfica del valor absoluto de los errores para las aproximaciones de la segunda derivada.

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))

fig.update_layout(
    title="Gráfica de errores segunda derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

d)  $f(x)=(cos\,3x)^2-e^{2x}$, $x\in [0,\pi/2]$

```{python}
#| code-fold: true
#| fig-align: 'center'


f = lambda x: (np.cos(3*x)**2-np.exp(2*x))

x_values = np.linspace(0, np.pi/2, 200)

plt.figure(figsize=(8,6))
plt.plot(x_values,  f(x_values), color = "darkred", linewidth=1.5)
plt.grid()
plt.show()
```

Primera derivada

```{python}
#| code-fold: true
#| warning: false
#| message: false

derf = lambda x: -3*np.sin(6*x)-np.exp(2*x)*2

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_005 = nd.Derivative(f, step=0.05, method='central', order=2)


fig = go.Figure()
# Aproximación de la derivada con los tamaños de paso 
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_005(x_values), mode='lines', name='h=0.05', line=dict(color='royalblue', width=1)))
# Aproximación de la derivada con derivative de Scipy
fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))
# Derivada "exacta"
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=1)))

fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la primera derivada

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))

fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Segunda derivada

```{python}
#| code-fold: true
#| warning: false

dderf = lambda x: -18*np.cos(6*x)-4*np.exp(2*x)

# Funciones de numdifftools para la segunda derivada
ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_005 = nd.Derivative(f, step=0.05, method='central', order=2, n = 2)

fig = go.Figure()
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_005(x_values), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la segunda derivada

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))

fig.update_layout(
    title="Gráfica de errores segunda derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

# Ejericicio 2

Aproximar las siguientes integrales con la función `integrate.quad` (de SciPy) y con el método de Montecarlo, en cada caso hacer una gráfica de la función e indicar el área bajo la curva.

a)  

\begin{equation}
\int_0^1 e^{-x^2}\,dx
\end{equation} Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'

f= lambda x: np.exp(-x ** 2)
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =500000

ymax = 1
ymin = -1

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = np.abs(y) <= abs(f(x))
puntos_in = puntos_in * np.sign(y)== np.sign(f(x))
puntos_in_positivo = puntos_in *(1 == np.sign(f(x)))
puntos_in_negativo = puntos_in *(-1 == np.sign(f(x)))

puntos_out = ~ puntos_in
puntos_out_positivo = puntos_out * (1 == np.sign(y))
puntos_out_negativo = puntos_out * (-1 == np.sign(y))



x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))

plt.plot(x[puntos_in_positivo], y[puntos_in_positivo], 'o', color="green", label= "Puntos in +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_in_negativo], y[puntos_in_negativo], 'o', color="red", label= "Puntos in -", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_positivo], y[puntos_out_positivo], 'o', color="blue", label= "Puntos out +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_negativo], y[puntos_out_negativo], 'o', color="skyblue", label= "Puntos out -", alpha=0.5, markersize=2.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in_positivo)/(sum(puntos_in_positivo) + sum(puntos_out_positivo))) + (b-a) * ymin * (sum(puntos_in_negativo)/(sum(puntos_in_negativo) + sum(puntos_out_negativo))) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

b)  

\begin{equation}
\int_0^\pi sen(x^2)\,dx
\end{equation}

Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'

f= lambda x: np.sin(x ** 2)
  
a = 0
b = np.pi

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =500000

ymax = 1
ymin = -1

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = np.abs(y) <= abs(f(x))
puntos_in = puntos_in * np.sign(y)== np.sign(f(x))
puntos_in_positivo = puntos_in *(1 == np.sign(f(x)))
puntos_in_negativo = puntos_in *(-1 == np.sign(f(x)))

puntos_out = ~ puntos_in
puntos_out_positivo = puntos_out * (1 == np.sign(y))
puntos_out_negativo = puntos_out * (-1 == np.sign(y))



x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))

plt.plot(x[puntos_in_positivo], y[puntos_in_positivo], 'o', color="green", label= "Puntos in +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_in_negativo], y[puntos_in_negativo], 'o', color="red", label= "Puntos in -", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_positivo], y[puntos_out_positivo], 'o', color="blue", label= "Puntos out +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_negativo], y[puntos_out_negativo], 'o', color="skyblue", label= "Puntos out -", alpha=0.5, markersize=2.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()

  
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in_positivo)/(sum(puntos_in_positivo) + sum(puntos_out_positivo))) + (b-a) * ymin * (sum(puntos_in_negativo)/(sum(puntos_in_negativo) + sum(puntos_out_negativo))) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

c)  

\begin{equation}
\int_0^\pi \frac{sen(x)}{x}\,dx
\end{equation}

Gráfica de la función y área bajo la curva.

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: np.sin(x)/x
  
a = 0
b = np.pi


x_values = np.linspace(a, b, 100)


plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()

  
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)
  
x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

d)  

\begin{equation}
\int_0^\infty e^{-x^2} cos(x) \,dx
\end{equation} Gráfica de la función y *área bajo la curva*.

```{python}
import numpy as np
import matplotlib.pyplot as plt

f = lambda x: np.exp(-x**2) * np.cos(x)

a = 0
b = 8  # Approximate infinity (since e^{-x^2} decays rapidly)

x_values = np.linspace(a, b, 1000)  # More points for smoother curve

plt.figure(figsize=(8, 6))
plt.plot(x_values, f(x_values), label="$e^{-x^2} \cos(x)$", color="blue")
plt.fill_between(x_values, 0, f(x_values), color="green", alpha=0.3, label="Área bajo la curva")
plt.xlabel("$x$")
plt.ylabel("$f(x)$")
plt.title("Gráfica de $e^{-x^2} \cos(x)$ y área bajo la curva")
plt.grid(True, linestyle='--', alpha=0.5)
plt.legend()
plt.show()

  
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)
  
x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

e)  

\begin{equation}
\int_0^1 x^x \,dx
\end{equation} Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: x**x
  
a = 0
b = 1


x_values = np.linspace(a, b, 100)


plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()

  
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)
  
x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

f)  

\begin{equation}
\int_1^5 e^{-x^2} x^3 dx
\end{equation} Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: np.exp(-x**2)*x**3
  
a = 1
b = 5


x_values = np.linspace(a, b, 100)


plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()

  
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)
  
x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

g)  

\begin{equation}
\int_0^1 \sqrt{1-x^2} dx
\end{equation}

Gráfica de la función y área bajo la curva

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: np.sqrt(1-x**2)
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

h)  

\begin{equation}
\int_0^\infty \frac{x}{e^x-1} dx
\end{equation} Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: x/np.exp(x-1)
  
a = 0
b = inf

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=0.5)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

i)  

\begin{equation}
\int_0^1 \frac{1}{\sqrt{x^4+1}} dx
\end{equation} Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: 1/np.sqrt(x**4+1)
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="green", alpha=10)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="red", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

# Ejercicio 3

Aproximar las siguientes integrales dobles y triples, llevar a cabo la gráfica cuando se indique y comparar con el valor *exacto* de la integral.

a)  Realizar gráfica

\begin{equation}
\int_{-1}^{1}\int_1^2 (3y^2-x^2+5) dx dy
\end{equation} Gráfica de la función y *área bajo la curva*

```{python}
x = np.linspace(1, 2, 50)
y = np.linspace(-1, 1, 50)
X, Y = np.meshgrid(x, y)

# Nueva función
Z = 3 * Y**2 - X**2 + 5

# Superficie principal
surface = go.Surface(x=X, y=Y, z=Z, colorscale='viridis', opacity=0.9)

# Pared en x = 1
X_wall1, Y_wall1 = np.meshgrid(np.ones_like(y), y)
Z_wall1 = np.vstack([np.zeros_like(y), 3 * Y_wall1[0]**2 - 1 + 5])  # f(1, y)

# Pared en x = 2
X_wall2, Y_wall2 = np.meshgrid(2 * np.ones_like(y), y)
Z_wall2 = np.vstack([np.zeros_like(y), 3 * Y_wall2[0]**2 - 4 + 5])  # f(2, y)

# Pared en y = -1
X_wall3, Y_wall3 = np.meshgrid(x, -1 * np.ones_like(x))
Z_wall3 = np.vstack([np.zeros_like(x), 3 * 1 - X_wall3[0]**2 + 5])  # f(x, -1)

# Pared en y = 1
X_wall4, Y_wall4 = np.meshgrid(x, np.ones_like(x))
Z_wall4 = np.vstack([np.zeros_like(x), 3 * 1 - X_wall4[0]**2 + 5])  # f(x, 1)

# Convertir las paredes a superficies
walls = [
    go.Surface(x=X_wall1, y=Y_wall1, z=Z_wall1, colorscale='Blues', showscale=False, opacity=0.5),
    go.Surface(x=X_wall2, y=Y_wall2, z=Z_wall2, colorscale='Blues', showscale=False, opacity=0.5),
    go.Surface(x=X_wall3, y=Y_wall3, z=Z_wall3, colorscale='Blues', showscale=False, opacity=0.5),
    go.Surface(x=X_wall4, y=Y_wall4, z=Z_wall4, colorscale='Blues', showscale=False, opacity=0.5)
]

# Plano base en Z=0
base = go.Surface(x=X, y=Y, z=np.zeros_like(Z), colorscale='Blues', showscale=False, opacity=0.3)

# Configurar la figura
fig = go.Figure(data=[surface, base] + walls)

fig.update_layout(
    title="Superficie f(x,y) = 3y² - x² + 5 y volumen",
    scene=dict(
        xaxis_title="X",
        yaxis_title="Y",
        zaxis_title="Z",
        xaxis=dict(range=[0.8, 2.2]),
        yaxis=dict(range=[-1.2, 1.2]),
        zaxis=dict(range=[0, np.max(Z) + 1])
    )
)

fig.show()

```

```{python}
f = lambda y, x: 3 * y**2 - x**2 + 5


integrate.dblquad(f,-1 , 1, 1, 2)
```

Comparar con la integral exacta

```{python}
#| code-fold: true

integral_exacta = 22/3
error_absoluto = abs(integral_exacta - integral[0])
print(f'El error absoluto es:{error_absoluto}')
```

b)  

\begin{equation}
\int_{0}^{6}\int_1^5 \sqrt{x+4y} dx dy
\end{equation}

```{python}
f = lambda y, x: np.sqrt(x+4**y)

integrate.dblquad(f,0 , 6, lambda y:1, lambda y:5)
```

c)  

\begin{equation}
\int_{1}^{e}\int_0^{log(x)} x^3 dx dy
\end{equation}

```{python}
f = lambda y, x: x**3
integrate.dblquad(f,1, np.e, lambda x:0 , lambda x:np.log(x))
```

d)  

\begin{equation}
\int\int_D 30ye^x dx dy
\end{equation}

Donde $D\subset \mathbb{R}^2$ es la región en la siguiente gráfica.

```{python}
#| code-fold: true
#| fig-align: 'center'




x_val = np.array([0,4])
y_val1 = np.array([0, 1])
y_val2 = np.array([0, 4])

plt.figure(figsize=(8,6))
plt.plot(x_val, y_val1)
plt.plot(x_val, y_val2)
plt.fill_between(x_val, y1=y_val1, y2=y_val2, color="firebrick", alpha=0.5)
plt.grid()
plt.show()

  
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

f = lambda y, x: 30 * y * np.exp(x)

integral = integrate.dblquad(f, 0, 4, lambda x: x/4, lambda x: x)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

En este caso el valor exacto de la integral es $\frac{225}{8} (5e^4-1)$. Se calcula el error absoluto.

```{python}
#| code-fold: true

integral_exacta = 225/8*(5*np.exp(4)-1)
error_absoluto = abs(integral_exacta - integral[0])
print(f'El error absoluto es:{error_absoluto}')
```

e)  

\begin{equation}
\int\int \int_B z e^{x+y} dx\, dy\, dz, \, B=[0,1] \times [0,1] \times [0,1]
\end{equation}

```{python}
f = lambda z, y, x: z * np.exp(x + y)

integrate.tplquad(f,0, 1, lambda x: 0,lambda x: 1,lambda x, y: 0,lambda x, y: 1)
```

f)  

\begin{equation}
\int_0^1 \int_0^x \int_0^y (y+xz) dz\, dy\, dx
\end{equation}

```{python}

f = lambda z, y, x: y + x * z

integrate.tplquad(f, 0, 1, lambda x: 0, lambda x: x,lambda x, y: 0, lambda x, y: y)


```

# Ejercicio 4

De [scipy.stats](@https://docs.scipy.org/doc/scipy/reference/stats.html) elige alguna distribución de probabilidad continua, realiza la gráfica y encuentra la probabilidad que la variable aleatoria tome un valor en un intervalo dado. Compara el resultado con el método `cdf`.

Como ejemplo consideraremos la distribución gamma, cuya función de densidad está dada por

\begin{equation}
f(x, a)= \frac{x^{a-1} e^{-x}}{\Gamma (a)}
\end{equation}

Gráficamos la función de densidad con un valor de $a = 1.9$.

```{python}
#| code-fold: true
#| fig-align: 'center'

from scipy.stats import gamma
a = 1.9

x_values = np.linspace(0 , gamma.ppf(0.99, a), 500)

plt.figure(figsize=(8,6))
plt.plot(x_values, gamma.pdf(x_values, a), label="Función de densidad")
plt.grid()
plt.legend()
plt.show()


```

Elegimos el intervalo $[1,3]$ para calcular la integral.

```{python}
#| code-fold: true
#| fig-align: 'center'

a1 = 1
b1 = 3

x_values = np.linspace(0 , gamma.ppf(0.99, a), 500)

plt.figure(figsize=(8,6))
plt.plot(x_values, gamma.pdf(x_values, a), label="Función de densidad")
plt.fill_between(np.linspace(a1,b1, 500), y1=0, y2=gamma.pdf(np.linspace(a1,b1, 500), a), color="green", alpha=0.5)
plt.grid()
plt.legend()
plt.show()


```

Se obtiene la integral con `integrate.quad`

```{python}
#| code-fold: true

integral = integrate.quad(gamma.pdf, a1, b1, args = (a,))

print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

Ahora se obtiene el valor por medio del método `cdf` (cumulative distribution function).

```{python}
gamma.cdf(3, a) - gamma.cdf(1, a)
```
